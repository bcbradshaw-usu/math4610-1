
# Math 4610 Table of Contents for Lectures:

The following list includes links to the lectures in Math 4610.

  * **Lecture 1.** 
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_01/md/lecture_01)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_01/pdf/lecture_01.pdf)

     - The course syllabus,
     - command windows/terminals, Cygwin,
     - coding and compiling in an example: (hello world!),
     - Github and homework, and 
     - homework tasksheets (where to start). 


  * **Lecture 2.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_02/md/lecture_02)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_02/pdf/lecture_02.pdf)

     - General repositories creation,
     - homework repositories,
     - some intuition about finite precision in number representation,
     - a coding example for determining machine precision, and
     - an introduction to roundoff error. 

  * **Lecture 3.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_03/md/lecture_03)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_03/pdf/lecture_03.pdf)

     - Measuring errors using absolute and relative errors,
     - types of errors the arise for computational scientists must deal with,
       and
     - shared libraries an introduction

  * **Lecture 4.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_04/md/lecture_04)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_04/pdf/lecture_04.pdf)

     - More on shared libraries - jar files, python, and other utilities, and
     - writing a software manual for the codes you create.

  * **Lecture 5.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_05/md/lecture_05)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_05/pdf/lecture_05.pdf)

     - Using a Version Control System (VCS) to maintain codes,
     - using git for development of computer codes,
     - accessing content from Github using git, and
     - coding up an approximation of the derivative of a real-valued function of
       one independent variable.

  * **Lecture 6.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_06/md/lecture_06)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_06/pdf/lecture_06.pdf)

     - Definition of truncation error in approximations,
     - more on the approximation of the derivative of a real-valued function,
     - a brief review of Taylor series,
     - trunction error in the derivative approximation, and
     - comparing roundoff error and truncation error the in the derivative
       approximation.

  * **Lecture 7.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_07/md/lecture_07)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_07/pdf/lecture_07.pdf)

     - Higher order approximation of the derivative of a function,
     - impact of error on the higher order approximation of the derivative,
     - some information on formatting results and output,
     - basics for html, xhtml, and markdown, LaTeX,
     - the software manual format/template and Jekyll, and
     - using "git push/pull" to make changes on Github.

  * **Lecture 8.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_08/md/lecture_08)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_08/pdf/lecture_06.pdf)

     - The general root finding problem for functions of one variable,
     - examples of root finding problems,
     - general classes of functions (continuous or smooth) in the root finding
       problem, and
     - development of iterative methods for the root finding problem.

  * **Lecture 9.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_09/md/lecture_09)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_09/pdf/lecture_09.pdf)
     - Transformation of the root finding problem into a fixed point problem,
     - lack of uniqueness of the fixed point equation,
     - definition of fixed point iteration,
     - a simple code to implement fixed point iteration for finding roots, and
     - convergence of fixed point iteration using Taylor series expansions,

  * **Lecture 10.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_10/md/lecture_10)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_10/pdf/lecture_10.pdf)

     - The Intermediate Value Theorem and the Bisection Method,
     - a code to implement the Bisection method,
     - a software page for the Bisection method with formatting,
     - convergence of the Bisection method, and
     - an alternative methods that specifies the exact number of iterations of
       bisection needed to achieve accuracy.

  * **Lecture 11.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_11/md/lecture_11)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_11/pdf/lecture_11.pdf)

     - Differentiable functions in the root finding problem,
     - approximation of functions using the tangent line,
     - definition of Newton's Method for root finding,
     - conditions needed for Newton's method to converge to a root, and
     - writing code to implement Newton's method.

  * **Lecture 12.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_12/md/lecture_12)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_12/pdf/lecture_12.pdf)

     - Convergence of Newton's method and second order accuracy,
     - definitions of linear convergence, quadratic convergence and super-linear
       convergence, and
     - proving convergence with Taylor series expansions.

  * **Lecture 13.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_13/md/lecture_13)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_13/pdf/lecture_13.pdf)

     - Approximation of Newton's method using the Secant method,
     - reasons for using the Secant method instead of Newton's method,
     - conditions for the secant method to work, and
     - development of an algorithm for the secant method, along with code to
       do the work.

  * **Lecture 14.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_14/md/lecture_14)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_14/pdf/lecture_14.pdf)

     - Hybrid methods for root finding,
     - reduction of error in approximating the location of a root in the
       Bisection method,
     - using Bisection combined with Newton's method to find a root,
     - using Bisection combined with the Secant method to find a root,
     - coding hybrid methods for for root finding. 

  * **Lecture 15.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_15/md/lecture_15)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_15/pdf/lecture_15.pdf)

     - Finding multiple roots of a function using a divide and conquer approach,
     - locating multiple roots, for a real-valued function, and
     - an example of a function with multiple roots on a closed and bounded
       interval.

  * **Lecture 16.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_16/md/lecture_16)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_16/pdf/lecture_16.pdf)

     - Using the Intermediate Value Theorem to bracket roots on some interval,
     - sampling the function on the interval in question, and
     - turning the subintervals into input for the hybrid methods developed in
       previous lectures, and
     - refining the sampling to pick up more roots.

  * **Lecture 17.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_17/md/lecture_17)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_17/pdf/lecture_17.pdf)

     - Parallelizing the problem of locating multiple roots for a real-valued
       function, and
     - developing algorithms using multi-core programming environments, and
     - using OpenMP to control parallelization of the algorithm and a meands to
       write code to solve the problem.

  * **Lecture 18.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_18/md/lecture_18)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_18/pdf/lecture_18.pdf)

     - Accessing OpenMP functionality,
     - OpenMP directives embedded in comment lines in codes,
     - OpenMP runtime functions and linking the runtime library during
       compilation, and
     - setting environment variables outside the compilation and execution of
       parallel codes using OpenMP.

  * **Lecture 19.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_19/md/lecture_19)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_19/pdf/lecture_19.pdf)

     - The Hello World application in OpenMP,
     - a description parallel regions in codes through the Hello World example,
       and
     - a closer look at OpenMP directives. 

  * **Lecture 20.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_20/md/lecture_20)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_20/pdf/lecture_20.pdf)

     - The fork-join execution model used by OpenMP,
     - generation of threads that work asynchronously, and
     - synchronization of worker threads in OpenMP.

  * **Lecture 21.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_21/md/lecture_21)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_21/pdf/lecture_21.pdf)

     - The memory model used by OpenMP,
     - shared variables,
     - private variables, and
     - memory models that obey consistency rules.

  * **Lecture 22.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_22/md/lecture_22)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_22/pdf/lecture_22.pdf)

     - Back to root finding problem,
     - writing code that takes advantage of the independence of the searches
       in the subintervals, and
     - code to implement the algorithm for the multiple root finding problem.

  * **Lecture 23.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_23/md/lecture_23)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_23/pdf/lecture_23.pdf)

     - Another example, Monte Carlo integration over a finite interval,
     - deriving a formula for the computing approximate values for a given
       definite integral, 
     - coding up this embarrasingly parallel algorithm, and
     - some examples.

  * **Lecture 24.**
[> > go there](https://jvkoebbe.github.io/math4610/lectures/lecture_24/md/lecture_24)
[(pdf)](https://jvkoebbe.github.io/math4610/lectures/lecture_24/pdf/lecture_24.pdf)








     - building a software manual.



     - coding the secant method, and
     - accuracy of the Secant method in comparison to Bisection and Newton's
       method, and
     - a summary of properties for root finding methods.

     - Finding multiple roots for functions of more than one variable,
     - divide and conquer strategies, and
     - application of multicore programming strategies.


     - Linaear systems of equations,
     - transforming a linear systems into a matrix equation,
     - solution of small linear systems using Gaussian elimination, and
     - elementary row operations.
     - Coding up Gaussian elimination for square linear systems of equations,

     - Exam I

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Truncation Error versus Roundoff Error} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Interval Analysis and the accumulation of roundoff error. Interval
            analysis allows a computational mathematicians to determine bounds
            on how errors accumulate over a large number of computations.
      \item Another related topic involves selecting \lq\lq stable\rq\rq
            algorithms for solution of real problems. Stable algorithms are less
            sensitive to accumulation of errors.
      \item Determining the efficiency of an algorithm. An effective means for
            determining efficiency is to count the number of Floating Point
            OPerations (flops) it takes to complete the algorithm.
      \item Tradeoffs between accuracy of an approximation versus efficiency of
            the algorithm used to compute the approximation will be discussed in
            terms of the examples already presented to this point.
      \item Ideas on practical methods to efficiently compute the number of
            flops needed to complete an algorithm. 
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Solution of Linear Systems of Equations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Gaussian elimination and implementation of row reduction operations.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Solution of Linear Systems of Equations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Back-substitution and the solution of linear systems of equations.
      \item How to measure errors in the solution of linear equations in terms
            of norms.
      \item Standard norms in computational mathematics.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Solution of Linear Systems of Equations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item LU factorization of square matrices.
      \item Rewrite of a linear system of equations using LU factorization.
      \item Forward substitution for intermediate solution of linear systems.
      \item LU factorization and solution of linear systems of equations.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Solution of Linear Systems of Equations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Comparisons for Gaussian elimination and LU factorization for
            solving linear systems of equations.
      \item Number of Floating Point Operations (flops) by introducing counters
            and the size of the linear system is increases.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Solution of Linear Systems of Equations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Reusable codes and putting together shared libraries from codes that
            can easily be used by others.
      \item Building examples of linear system of equations and using benchmarks
            to test codes. ORNL/nanet 
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Matrix Operations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Computation of the sum of vectors.
      \item Computation of inner products of vectors.
      \item Computation of cross products of vectors.
      \item Computation of matrix-vector products.
      \item Computation of matrix-matrix products.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Stationary Iterative Method for Solving Linear Systems}
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Functional Iteration for System Equations.
      \item Jacobi Iteration.
      \item Gauss-Seidel Iteration.
      \item Analysis of these methods.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Stationary Iterative Method for Solving Linear Systems}
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Gauss-Seidel Iteration.
      \item Recursion versus explicit evaluation of iteration methods.
      \item Analysis of Gauss-Seidel
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Parallel Algorithms for Solving Linear Systems} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Compiler options for optimization of a code.
      \item Hello world using OpenMP. 
      \item Using OpenMp to parallelize Jacobi Iteration. 
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Finding roots of nonlinear functions of one variable} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item The root finding problem.
      \item Functional Iteration for Root Finding.
      \item Convergence of Functional Iteration Via Fixed Point Theorems.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Finding roots of nonlinear functions of one variable} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item The Bisection Method.
      \item The Intermediate Theorem for Continuous Functions on a Closed
            Interval.
      \item Accuracy versus Number of Iterations in the Bisection Method.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Estimating Eigenvalues of a Square Matrix} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item The Rayleigh Quotient for Eigenpairs of a Square Matrix.
      \item The Power Method for estimating the largest eigenvalue of a matrix.
      \item Why the Power Method Works.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Inverse Iteration for the Smallest Eigenvalue} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Properties of Eigenvalues of Matrices Using Shifting
      \item The Inverse Iteration Method for estimating the smallest of a
            matrix.
      \item Using Shifting, Parallel Implementation to Search for Eigenvalues
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: The QR Factorization of a Matrix} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item QR factorization of a matrix.
      \item Gram-Schmidt Orthogonalization of Vectors.
      \item Modified Gram-Schmift Orthogonalization for added stability of the
            computational algorithm.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: The QR Factorization for Solving Systems of Linear
         Equations} 
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item The matrix operations needed to solve a linear system.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: The QR Factorization for Solving Least Squares
         Problems}
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item Full Column Rank Problems and the thin QR.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: The QR Factorization for Eigenvalue Problems}
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item The QR algorithm.
      \item Why the QR algorithm works.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \item {\bf Lecture: Quantum Computing - IBMQ}
    \begin{list}{$\bullet$}{\usecounter{beans} \parsep=0pt \listparindent=0pt
    \topsep=0pt \rightmargin=.35in \leftmargin=.35in \labelsep=5 pt
    \itemsep=2pt}
      \item Questions from the previous lecture.
      \item What is quantum computing?
      \item Accessing IBMQ.
    \end{list}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{enumerate}
\end{document}
