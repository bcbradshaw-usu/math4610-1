
<!DOCTYPE html>
<html>

<head>
  <title> Math 4610 Fundamentals of Computational Mathematics Homework </title>
  <link href="homework.css" rel="stylesheet" type="text/css" />
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript" async
    src="https://example.com/MathJax.js?config=TeX-AMS_CHTML">
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>
<body>

<hr>

<h1> Math 4610 Fundamentals of Computational Mathematics  - Topic 12. </h1>

<hr>

Most mathematical problems require the use of approximations as a part of the
solution process. For example, the solution of the simple ordinary differential
equation
\[
  {{dy}\over{dt}} = -2\ y
\]
with initial condition, \(y(0)=1\), is the function
\[
  y(t) = e^{-2t}
\]
You can check this on your own. This is a single term that seems nice and tidy
for predicting values of the solution to the differential equation. However, due
to the fact that the number \(e=2.71828...\) is an irrational number any
evaluation will be an approximation at best. For certain values like \(t=0\) the
exponential can be evaluated exactly since \(e^0=1\). However, for just about
any other number all we can do is approximate the value based on mathematical
formulas.

From any standard second semester engineering calculus course, an infinite
series representation of the exponential function is given by
\[
  e^x = 1 + x + {1\over 2} x^2 + {1\over 6} x^3 + \cdots
      = \sum_{k=0}^\infty {{x^k}\over{k!}}
\]
Of course, this being an infinite series, the best we can do is sum a finite
number of terms and neglect/truncate the rest of the infinite series.

Mathematically, we know that the series converges rapidly to an output value
given any reasonable input value. It may take a few (or a lot of) terms, but a
truncated series
\[
  e^x \approx \sum_{k=0}^N {{x^k}\over{k!}}
\]
for some, \(N>0\), can be used to approximate the exponential function. In this
example, there are a couple of practical problems that still need to be
addressed. First, if we truncate the infinite sum to a finite number of terms,
\(N>0\), how good is the approximation? As we will see below, the truncation of
the series can be analyzed mathematically using Taylor series expansions.

The second problem involves errors in number representation and errors in
arithmetic operations on any/all computers. That is, due to the finite resources
(memory/disk space) available on a computer, we will run into problems for
either very small or very large input values to the exponential function.

The first problem is due to the truncation error which is an artifact of
replacing a mathematically exact model with some approximation. For the example,
once a value of \(N>0\) is chosen, the truncation uses a finite number of terms
and creates an error dependent on an infinite number of neglected terms in the
series. Truncation error in any given problem needs to be analyzed
mathematically. The second problem is really beyond our control since it is due
to the particular computer and operating system we are using. We will treat the
problem of truncation error in this section and save the problem of round off
error and machine precision for another topic in the near future.

<hr>

<h2> Definition Of Taylor Series And Taylor Series With Remainders: </h2>

<hr>

In almost any calculus sequence, the topic of infinite series and in particular
Taylor series is discussed. A definition for Taylor series is the following.

<hr>

<dfn> <bold> Definition: </bold>
  Suppose that the function, \(f\), is a function with derivatives of all
  orders at a point, \(a\), in the domain of \(f\). Then the Taylor series of
  \(f\) about the point \(a\) is given by
  \[
    f(x) \sim f(a) + f'(a) ( x - a ) + {1\over 2} f''(a) ( x - a )^2 + \cdots
          = \sum_{k=0}^\infty\ {{f^{(k)}}\over{k!}}\ ( x - a )^k
  \]
  where \(f^{(k)}(a)\) denotes the \(k^{th}\) derivative of \(f\) at \(a\) and
  \(k!=k(k-1)(k-2)\ldots (2)(1)\) is the \(k^{th}\) factorial and we use
  \(0!=1\).
</dfn>

<hr>

Students should be able to produce the Taylor series of simple functions like
the trigonometric functions or examples like \(f(x)=ln(1+x)\). If you are a
little foggy on the details, there are examples all over the internet or you can
refer to any book that presents topics in engineering calculus. In the next
topic in the course a few helpful/standard examples will be reviewed.

An important note at this point in the presentation is that writing down a
Taylor series representation does not guarantee the infinite series will
converge for all points in the domain of a function. The geometric series will
provide one such example. Part of the work on power series in a calculus course
is to determine the interval of convergence. This is typically done via the
ratio test which we will not cover here. Students should review these ideas if
calculus seems to be in the distant past. 

For some of the analysis of approximations it will be important to know how to
apply the Taylor series with remainder. The definition we need is the following.

<hr>

<dfn> <bold> Definition: </bold>
  Suppose that the function, \(f\), is a function with \(n+1\) continuous
  derivatives at a point, \(a\), in the domain of the function. Then, the Taylor
  series with remainder is
  \[
    f(x) \sim \sum_{k=0}^n\ {{f^{(k)}(a)}\over{k!}}\ ( x - a )^k
                   + R_f(a,n)
  \]
  where
  \[
    R_f(a,n) = {{f^{n+1}(\xi)}\over{(n+1)!}}\ ( x - a )^{n+1}
  \]
  and \(\xi\) is a point between \(x\) and \(a\).
</dfn>

<hr>

The remainder in this definition can be used to establish upper bounds on the
truncation error as will be seen in the examples in this topic.

<hr>

<h2> Increment Form of the Taylor Series: </h2> 

<hr>

Computational mathematicians should be able to use Taylor series with ease in
the analysis of numerical methods. There are several different, but equivalent
forms of the Taylor series. For the purposes in this course, we will use the
\(h\) or increment form for Taylor series expansions. To get to the appropriate
form, letting \(h=x-a\) in either the Taylor series definition or the Taylor
series with remainder definition in the previous section. Substituting this
change of variables and doing some simplification gives
\[
  f(a+h) \sim f(a) + f'(a) h + {1\over 2} f''(a) h^2 + \cdots
          = \sum_{k=0}^\infty\ {{f^{(k)}(a)}\over{k!}}\ h^k
\]
or using the Taylor series with remainder
\[
    f(a+h) \sim \sum_{k=0}^N\ {{f^{(k)}(a)}\over{k!}}\ h^k
                   + R_f(a,N)
\]
where
\[
  R_f(a,N) = {{f^{N+1}(\xi)}\over{(N+1)!}}\ h^{N+1}
\]
This form allows us to analyze approximations of functions. As an example, let's
consider the example at the beginning of the this topic.

Using the \(h\)-form of the Taylor series expansion for the natural exponential
the solution of the differential equation can be represented as
\[
  y(a+h) = e^{-2(a+h)} \sim \sum_{k=0}^N\ {{y^{(k)}(a)}\over{k!}}\ h^N
                   + R_y(a,N)
\]
and
\[
  R_y(a,N) = {{y^{N+1}(\xi)}\over{(N+1)!}}\ h^{N+1}
\]
To be a bit more specific, consider the case when \(N=3\) and \(a=1.0\). Then we
can write
\[
  y(1.0+h) = y(1.0) + y'(1.0)\ h + {1\over{2!}}\ y''(1.0)\ h^2
               + {1\over{3!}}\ y'''(1.0)\ h^3 + 
               + {1\over{4!}}\ y^{(4)}(\xi)\ h^4
\]
We can replace the derivatives in the expression using
\[
   y=e^{-2t}\ \ \ \rightarrow\ \ \ 
      y'=-2e^{-2t},\ \  y''=4e^{-2t},\ \  y'''=-8e^{-2t},\ \  y''''=16e^{-2t}
\]
to obtain
\[
  y(1.0+h) = e^{-2} - 2 e^{-2}\ h + 2 e^{-2}\ h^2
               - {4\over 3}\ e^{-2} \ h^3 
               + {1\over{24}}\ e^{\xi}\ h^4
\]
where \(\xi\) is a value between \(t=1\) and \(t=1+h\).

The first four terms in the last expression define a cubic polynomial which is
called the Taylor polynomial of degree three. The Taylor polynomial defines an
approximation of the solution. The last term accounts for truncating an infinite
number of terms in the Taylor series. The remainder term will allow us to obtain
a bound on the error in the approximation. That is, if we use
\[
  y(1.0+h) \approx e^{-2} - 2 e^{-2}\ h + 2 e^{-2}\ h^2
               - {4\over 3}\ e^{-2} \ h^3 
\]
we are neglecting the remainder term. The error in this approximation is
obtained by determining an upper bound on the absolute value of the remainder
term. So, for our example with \(E\) denoting the error at \(t=1\),
\[
  E = \left| {1\over{24}}\ e^{\xi}\ h^4 \right| =
          {1\over{24}}\ \left| e^{\xi}\ \right|\ h^4 
                \leq {1\over{24}}\ \left| e^0\ \right|\ h^4
\]
Note that \(0<e^-2<e^0\). As \(h\) is pushed towards zero, the error will be
reduced proportional to \(h^4\). If we were to choose \(h=0.1\) then the error
will be bounded as
\[
  E \leq {1\over{24}} 10^{-4} 
\]
The question is whether or not the error is acceptable. If not, we may want to
add more terms to the approximation.

We will do a lot of these types of computations throughout the semester. In
particular, when we analyze root finding problems, we will use Taylor series to
determine whether or not the truncation error will be reduced to zero in some
sense and if this is the case, how fast the error is reduced.

</body>
</html>
